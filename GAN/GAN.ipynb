{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist =tf.keras.datasets.mnist\n",
    "(train_images,_), (_,_) = mnist.load_data()\n",
    "train_images=train_images.reshape(train_images.shape[0],28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47040000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.data.Dataset import from_tensor_slices\n",
    "train_images=(train_images-127.5)/127.5\n",
    "BUFFER_SIZE=60000\n",
    "BATCH_SIZE=256\n",
    "train_dataset=from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERADOR DE RUIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 12544)             1254400   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 14, 14, 128)       819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 14, 14, 64)        204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2D  (None, 28, 28, 1)         1601      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2280961 (8.70 MB)\n",
      "Trainable params: 2280577 (8.70 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                    Reshape, \n",
    "                                    Conv2DTranspose, \n",
    "                                    BatchNormalization,\n",
    "                                    LeakyReLU)\n",
    "\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "\n",
    "    model.add(Reshape((7,7,256)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Conv2DTranspose(1, (5,5), strides=(2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_generator_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
